{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import all the libraries and read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from Utils.calculate_metrics import *\n",
    "\n",
    "from joblib import dump, load\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7200, 139), (800, 139))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./Data/train.csv', index_col='id')\n",
    "test_data = pd.read_csv('./Data/test.csv', index_col='id')\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "preprocess_data_base() got an unexpected keyword argument 'selected_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 55\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data_selected, label\n\u001b[1;32m     54\u001b[0m train_df, train_label \u001b[38;5;241m=\u001b[39m preprocess_data_base(train_data)\n\u001b[0;32m---> 55\u001b[0m test_df, test_label \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data_base\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselected_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m train_df\u001b[38;5;241m.\u001b[39mshape, test_df\u001b[38;5;241m.\u001b[39mshape, train_label\u001b[38;5;241m.\u001b[39mshape, test_label\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mTypeError\u001b[0m: preprocess_data_base() got an unexpected keyword argument 'selected_features'"
     ]
    }
   ],
   "source": [
    "def preprocess_data_base(data: pd.DataFrame):\n",
    "    data = data.copy()\n",
    "    data = data[data[\"happiness\"] > 0]\n",
    "    \n",
    "    data.loc[:, \"survey_month\"] = data[\"survey_time\"].apply(lambda line: line.split(\" \")[0].split(\"/\")[1]).astype(\"int64\")\n",
    "    data.loc[:, \"survey_day\"] = data[\"survey_time\"].apply(lambda line: line.split(\" \")[0].split(\"/\")[2]).astype(\"int64\")\n",
    "    data.loc[:, \"survey_hour\"] = data[\"survey_time\"].apply(lambda line: line.split(\" \")[1].split(\":\")[0]).astype(\"int64\")\n",
    "    data = data.drop(columns='survey_time')\n",
    "    \n",
    "    data = data.drop(columns=['edu_other', 'property_other', 'invest_other', 'join_party'])\n",
    "\n",
    "    \n",
    "    label = data.pop('happiness')\n",
    "    return data, label\n",
    "\n",
    "def preprocess_data_dim60(train_data: pd.DataFrame, selected_features: list = None) -> pd.DataFrame:\n",
    "    data = train_data.copy()\n",
    "    data = data[data[\"happiness\"] > 0]\n",
    "    \n",
    "    # Feature engineering\n",
    "    data.loc[:, \"survey_month\"] = data[\"survey_time\"].apply(lambda line: line.split(\" \")[0].split(\"/\")[1]).astype(\"int64\")\n",
    "    data.loc[:, \"survey_day\"] = data[\"survey_time\"].apply(lambda line: line.split(\" \")[0].split(\"/\")[2]).astype(\"int64\")\n",
    "    data.loc[:, \"survey_hour\"] = data[\"survey_time\"].apply(lambda line: line.split(\" \")[1].split(\":\")[0]).astype(\"int64\")\n",
    "    data.loc[:, \"age\"] = 2015 - data[\"birth\"]\n",
    "\n",
    "    data = data.drop(columns='survey_time')\n",
    "    data = data.drop(columns=['edu_other', 'property_other', 'invest_other', 'join_party'])\n",
    "\n",
    "    # Replace NaN in specific columns with 0\n",
    "    for column in ['work_status', 'work_yr', 'work_type', 'work_manage', 's_work_status', 's_work_type']:\n",
    "        data.loc[data[column].isna(), column] = 0\n",
    "    \n",
    "    # Replace remaining NaN values with mode\n",
    "    data = data.fillna(data.mode().iloc[0])\n",
    "\n",
    "    # Replace negative values with the mode for integer columns\n",
    "    for column in data.columns:\n",
    "        if data[column].dtype == np.int64:\n",
    "            data.loc[data[column] < 0, column] = data[column].mode().iloc[0]\n",
    "    \n",
    "    if selected_features is None:\n",
    "        corr_matrix = data.corr(method='pearson', numeric_only=True)['happiness'][abs(data.corr(method='pearson', numeric_only=True)['happiness'])>0.05]\n",
    "        features = corr_matrix.index.values.tolist()\n",
    "        features.extend(['age'])  # Adding age explicitly as it is not necessarily part of correlation\n",
    "        data_selected = data[features]\n",
    "    else:\n",
    "        selected_features.append('happiness')\n",
    "        data_selected = data[selected_features]  # Ensure the selected features match\n",
    "\n",
    "    label = data_selected.pop('happiness')\n",
    "    return data_selected, label\n",
    "\n",
    "\n",
    "train_df, train_label = preprocess_data_base(train_data)\n",
    "test_df, test_label = preprocess_data_base(test_data)\n",
    "train_df.shape, test_df.shape, train_label.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Basic Modeling:\n",
    "\n",
    "#### 3.1 Support Vector Machine (SVM)\n",
    "\n",
    "**Our observations:**\n",
    "\n",
    "- SVM can't handle such complex cases. It tends to predict the majority class (Happiness = 4).\n",
    "- PCA can't improve the performance of SVM.\n",
    "\n",
    "**Conclusion:** SVM is not a good choice for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7882205513784462 Accuracy: 0.5739348370927319\n",
      "(array([], dtype=int64),)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "svc_rbf = svm.SVC(kernel='rbf', C=1)\n",
    "svc_rbf.fit(train_df, train_label)\n",
    "\n",
    "predict = svc_rbf.predict(test_df)\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "print(np.where(predict!=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7190, 4) (798, 4)\n",
      "MSE: 0.7882205513784462 Accuracy: 0.5739348370927319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 4)\n",
    "reduced_train = pca.fit_transform(train_df)\n",
    "reduced_test = pca.fit_transform(test_df)\n",
    "\n",
    "print(reduced_train.shape, reduced_test.shape)\n",
    "\n",
    "svc_rbf = svm.SVC(kernel='rbf')\n",
    "svc_rbf.fit(reduced_train, train_label)\n",
    "\n",
    "predict = svc_rbf.predict(reduced_test)\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "np.where(predict!=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Ridge Regression\n",
    "\n",
    "**Our observations:**\n",
    "- Betther than SVM when it comes to the mse. \n",
    "- Perform poorly in terms of the accuracy.\n",
    "- It seems underfit or the model is too simple for this dataset. We try to evaluate the model with training data but the model is not able to capture the complexity of the data.\n",
    "\n",
    "**Conclusion:**\n",
    "Ridge Regression is not a good choice for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5827067669172933 Accuracy: 0.5764411027568922\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "ridge = linear_model.Ridge()\n",
    "ridge.fit(train_df, train_label)\n",
    "\n",
    "predict = ridge.predict(test_df)\n",
    "predict = np.round(predict)\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Logistic Regression\n",
    "\n",
    "**Our observations:**\n",
    "- Similar to SVM, Logistic Regression can't handle such complex cases. It tends to predict the majority class (Happiness = 4).\n",
    "- PCA will even make the performance worse.\n",
    "\n",
    "**Conclusion:** \n",
    "Logistic Regression is not a good choice for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7882205513784462 Accuracy: 0.5739348370927319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model    \n",
    "from sklearn import metrics\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(train_df, train_label)\n",
    "\n",
    "predict = logistic.predict(test_df)\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "np.where(predict!=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.3922305764411027 Accuracy: 0.4523809523809524\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 8)\n",
    "reduced_train = pca.fit_transform(train_df)\n",
    "reduced_test = pca.fit_transform(test_df)\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(reduced_train, train_label)\n",
    "\n",
    "predict = logistic.predict(reduced_test)\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Advanced Modeling:\n",
    "\n",
    "### 4.1 LightGBM\n",
    "\n",
    "**Our observations:**\n",
    "\n",
    "\n",
    "**Conclusion:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1283\n",
      "[LightGBM] [Info] Number of data points in the train set: 7190, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 3.873435\n",
      "MSE: 0.5726817042606517 Accuracy: 0.600250626566416\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "lgbR = lgb.LGBMRegressor()\n",
    "lgbR.fit(train_df, train_label)\n",
    "\n",
    "predict = lgbR.predict(test_df)\n",
    "predict = np.round(predict)\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1283\n",
      "[LightGBM] [Info] Number of data points in the train set: 7190, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score -4.380637\n",
      "[LightGBM] [Info] Start training from score -2.798228\n",
      "[LightGBM] [Info] Start training from score -1.940224\n",
      "[LightGBM] [Info] Start training from score -0.500219\n",
      "[LightGBM] [Info] Start training from score -1.734462\n",
      "MSE: 0.656641604010025 Accuracy: 0.6102756892230576\n"
     ]
    }
   ],
   "source": [
    "lgbC = lgb.LGBMClassifier()\n",
    "lgbC.fit(train_df, train_label)\n",
    "\n",
    "predict = lgbC.predict(test_df)\n",
    "\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1283\n",
      "[LightGBM] [Info] Number of data points in the train set: 7190, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 3.873435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "MSE: 0.575187969924812 Accuracy: 0.5902255639097744\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "\n",
    "clf_lightgbm_modified=lgb.LGBMRegressor(metric='l2',colsample_bytree=0.8,learning_rate=0.1,\n",
    "                                             max_depth=7,min_child_weight=0,min_split_gain=0.1,\n",
    "                                             reg_alpha=1,reg_lambda=0.0001,subsample=0.5)   \n",
    "\n",
    "clf_lightgbm_modified.fit(train_df, train_label)\n",
    "\n",
    "predict = clf_lightgbm_modified.predict(test_df)\n",
    "predict = np.round(predict)\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 XGBoost\n",
    "\n",
    "**Our observations:**\n",
    "\n",
    "\n",
    "\n",
    "**Conclusion:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6290726817042607 Accuracy: 0.5651629072681704\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "xgboost = xgb.XGBRegressor()\n",
    "xgboost.fit(train_df, train_label)\n",
    "\n",
    "predict = xgboost.predict(test_df)\n",
    "\n",
    "predict = np.round(predict)\n",
    "\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.656641604010025 Accuracy: 0.5701754385964912\n"
     ]
    }
   ],
   "source": [
    "xgboost_modified=xgb.XGBRegressor(max_depth=4,min_child_weight=0.5,gamma=0.4,subsample=0.7,colsample_bytree=0.8,reg_alpha=1,reg_lambda=0.001)   \n",
    "\n",
    "xgboost_modified.fit(train_df, train_label)\n",
    "\n",
    "predict = xgboost_modified.predict(test_df)\n",
    "predict = np.round(predict)\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 LightGBM Essambled with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000574 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1283\n",
      "[LightGBM] [Info] Number of data points in the train set: 7190, number of used features: 75\n",
      "[LightGBM] [Info] Start training from score 3.873435\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "MSE: 0.5852130325814536 Accuracy: 0.5877192982456141\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "xgboost = xgb.XGBRegressor(max_depth=4,min_child_weight=0.5,gamma=0.4,subsample=0.7,colsample_bytree=0.8,reg_alpha=1,reg_lambda=0.001)   \n",
    "lgbm = lgb.LGBMRegressor(metric='l2',colsample_bytree=0.8,learning_rate=0.1,\n",
    "                                             max_depth=7,min_child_weight=0,\n",
    "                                             reg_alpha=1,reg_lambda=0.0001,subsample=0.5)   \n",
    "\n",
    "xgboost.fit(train_df, train_label)\n",
    "lgbm.fit(train_df, train_label)\n",
    "\n",
    "predict_xgboost = xgboost.predict(test_df)\n",
    "predict_lgbm = lgbm.predict(test_df)\n",
    "\n",
    "predict = (predict_xgboost + predict_lgbm) / 2\n",
    "\n",
    "predict = np.round(predict)\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "    \n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 41,  58,  64,  73, 112, 114, 124, 178, 183, 212, 214, 242, 277,\n",
       "        298, 309, 313, 341, 356, 366, 382, 392, 505, 549, 568, 584, 600,\n",
       "        603, 605, 612, 642, 661, 695, 720]),)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(predict==5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import all the libraries and read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "from joblib import dump, load\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7200, 139), (800, 139))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv('./Data/train.csv', index_col='id')\n",
    "test_data = pd.read_csv('./Data/test.csv', index_col='id')\n",
    "train_data.shape, test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7190, 136), (798, 136), (7190,), (798,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    data = data[data[\"happiness\"]>0]\n",
    "    \n",
    "    data[\"survey_month\"] = data[\"survey_time\"].transform(lambda line:line.split(\" \")[0].split(\"/\")[1]).astype(\"int64\")   #返回调查月：用空格来切分日期和时间，日期中第1项为月\n",
    "    data[\"survey_day\"] = data[\"survey_time\"].transform(lambda line:line.split(\" \")[0].split(\"/\")[2]).astype(\"int64\")   #返回调查日\n",
    "    data[\"survey_hour\"] = data[\"survey_time\"].transform(lambda line:line.split(\" \")[1].split(\":\")[0]).astype(\"int64\")   #返回调查小时\n",
    "    data=data.drop(columns='survey_time')\n",
    "    \n",
    "    data.drop(columns=['edu_other','property_other','invest_other', 'join_party'],inplace=True)  \n",
    "    data.fillna(data.mean(),inplace=True)\n",
    "    label = data.pop('happiness')\n",
    "\n",
    "    \n",
    "    return data, label\n",
    "\n",
    "\n",
    "\n",
    "def feature_engineering(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    pass\n",
    "    \n",
    "    return data\n",
    "\n",
    "train_df, train_label = preprocess_data(train_data)\n",
    "test_df, test_label = preprocess_data(test_data)\n",
    "train_df.shape, test_df.shape, train_label.shape, test_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Basic Modeling:\n",
    "\n",
    "#### 3.1 Support Vector Machine (SVM)\n",
    "\n",
    "**Our observations:**\n",
    "\n",
    "- SVM can't handle such complex cases. It tends to predict the majority class (Happiness = 4).\n",
    "- PCA can't improve the performance of SVM.\n",
    "\n",
    "**Conclusion:** SVM is not a good choice for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7894736842105263 Accuracy: 0.5726817042606517\n",
      "(array([666]),)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "\n",
    "svc_rbf = svm.SVC(kernel='rbf', C=1)\n",
    "svc_rbf.fit(train_df, train_label)\n",
    "\n",
    "predict = svc_rbf.predict(test_df)\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "print(np.where(predict!=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7190, 4) (798, 4)\n",
      "MSE: 0.7894736842105263 Accuracy: 0.5726817042606517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([666]),)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 4)\n",
    "reduced_train = pca.fit_transform(train_df)\n",
    "reduced_test = pca.fit_transform(test_df)\n",
    "\n",
    "print(reduced_train.shape, reduced_test.shape)\n",
    "\n",
    "svc_rbf = svm.SVC(kernel='rbf')\n",
    "svc_rbf.fit(reduced_train, train_label)\n",
    "\n",
    "predict = svc_rbf.predict(reduced_test)\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "np.where(predict!=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Ridge Regression\n",
    "\n",
    "**Our observations:**\n",
    "- Betther than SVM when it comes to the mse. \n",
    "- Perform poorly in terms of the accuracy.\n",
    "- It seems underfit or the model is too simple for this dataset. We try to evaluate the model with training data but the model is not able to capture the complexity of the data.\n",
    "\n",
    "**Conclusion:**\n",
    "Ridge Regression is not a good choice for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.6303258145363408 Accuracy: 0.5726817042606517\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "ridge = linear_model.Ridge()\n",
    "ridge.fit(train_df, train_label)\n",
    "\n",
    "predict = ridge.predict(test_df)\n",
    "predict = np.round(predict)\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Logistic Regression\n",
    "\n",
    "**Our observations:**\n",
    "- Similar to SVM, Logistic Regression can't handle such complex cases. It tends to predict the majority class (Happiness = 4).\n",
    "- PCA will even make the performance worse.\n",
    "\n",
    "**Conclusion:** \n",
    "Logistic Regression is not a good choice for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7894736842105263 Accuracy: 0.5726817042606517\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([718]),)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model    \n",
    "from sklearn import metrics\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(train_df, train_label)\n",
    "\n",
    "predict = logistic.predict(test_df)\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "np.where(predict!=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.8922305764411027 Accuracy: 0.43107769423558895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 8)\n",
    "reduced_train = pca.fit_transform(train_df)\n",
    "reduced_test = pca.fit_transform(test_df)\n",
    "\n",
    "logistic = linear_model.LogisticRegression()\n",
    "logistic.fit(reduced_train, train_label)\n",
    "\n",
    "predict = logistic.predict(reduced_test)\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Advanced Modeling:\n",
    "\n",
    "### 4.1 LightGBM\n",
    "\n",
    "**Our observations:**\n",
    "\n",
    "\n",
    "**Conclusion:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3098\n",
      "[LightGBM] [Info] Number of data points in the train set: 7190, number of used features: 132\n",
      "[LightGBM] [Info] Start training from score 3.873435\n",
      "MSE: 0.5952380952380952 Accuracy: 0.5864661654135338\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "import os\n",
    "\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "lgbm = lgb.LGBMRegressor()\n",
    "lgbm.fit(train_df, train_label)\n",
    "\n",
    "predict = lgbm.predict(test_df)\n",
    "predict = np.round(predict)\n",
    "\n",
    "mse = metrics.mean_squared_error(test_label, predict)\n",
    "accuracy = metrics.accuracy_score(test_label, predict)\n",
    "\n",
    "print('MSE:', mse, end=' ')\n",
    "print('Accuracy:', accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
